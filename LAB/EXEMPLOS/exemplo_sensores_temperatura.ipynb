{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922b93a7-648e-4c93-8ed8-7ad4ff9ebb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/cj/.local/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Instala o findspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b614d21-c8d5-4605-88fa-0e09d274c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Import required modules\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecb51c3-fca6-4a12-b5b8-5e1e70c4a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conector\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7195978-5eb2-41a4-805e-17570a57e85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:08:55 WARN Utils: Your hostname, cj resolves to a loopback address: 127.0.1.1; using 192.168.15.34 instead (on interface enp2s0)\n",
      "24/05/13 19:08:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/cj/.ivy2/cache\n",
      "The jars for the packages stored in: /home/cj/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f3cb5e16-060c-476a-960a-0c5f540370b7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 539ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f3cb5e16-060c-476a-960a-0c5f540370b7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/8ms)\n",
      "24/05/13 19:08:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/13 19:08:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Cria a sessão Spark\n",
    "spark = SparkSession.builder.appName(\"projeto\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7aa83e-1820-41d7-ae00-f749aa86825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma subscrição no tópico que tem o streaming de dados que desejamos \"puxar\" os dados.\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", \"vandas-deshboard-bronze\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80c51f7-e66b-4567-83c2-bb5d86563839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos o schema dos dados que desejamos capturar para análise (temperatura)\n",
    "esquema_dados_temp = StructType([StructField(\"leitura\", \n",
    "                                             StructType([StructField(\"temperatura\", DoubleType(), True)]), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9f321a-912d-4d6b-ba36-994c2d8ad039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos o schema global dos dados no streaming\n",
    "esquema_dados = StructType([ \n",
    "    StructField(\"id_sensor\", StringType(), True), \n",
    "    StructField(\"id_equipamento\", StringType(), True), \n",
    "    StructField(\"sensor\", StringType(), True), \n",
    "    StructField(\"data_evento\", StringType(), True), \n",
    "    StructField(\"padrao\", esquema_dados_temp, True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c855792e-b676-4d0c-a95c-067628683f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_sensor: string (nullable = true)\n",
      " |-- id_equipamento: string (nullable = true)\n",
      " |-- sensor: string (nullable = true)\n",
      " |-- data_evento: string (nullable = true)\n",
      " |-- padrao: struct (nullable = true)\n",
      " |    |-- leitura: struct (nullable = true)\n",
      " |    |    |-- temperatura: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Capturamos cada linha de dado (cada valor) como string\n",
    "df_conversao = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "# Parse do formato JSON em dataframe\n",
    "df_conversao = df_conversao.withColumn(\"jsonData\", from_json(col(\"value\"), esquema_dados)).select(\"jsonData.*\")\n",
    "\n",
    "df_conversao.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514b3f8b-9362-426b-b02d-7ec7a5e6bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeamos as colunas para simplificar nossa análise\n",
    "df_conversao_temp_sensor = df_conversao.select(col(\"padrao.leitura.temperatura\").alias(\"temperatura\"), \n",
    "                                               col(\"sensor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1b41a2b-fa89-4a77-8264-2ba720ce7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui temos o objeto que irá conter nossa análise, o cálculo da média das temperaturas por sensor\n",
    "df_media_temp_sensor = df_conversao_temp_sensor.groupby(\"sensor\").mean(\"temperatura\")\n",
    "\n",
    "# Renomeamos as colunas para simplificar nossa análise\n",
    "df_media_temp_sensor = df_media_temp_sensor.select(col(\"sensor\").alias(\"sensor\"), \n",
    "                                                   col(\"avg(temperatura)\").alias(\"media_temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3bde48-bebe-476a-905f-4efb566836b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:09:02 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-df681c48-1301-491f-ac26-6b4cfacf2768. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/05/13 19:09:02 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/05/13 19:09:03 WARN AdminClientConfig: The configuration 'key.deserializer' was supplied but isn't a known config.\n",
      "24/05/13 19:09:03 WARN AdminClientConfig: The configuration 'value.deserializer' was supplied but isn't a known config.\n",
      "24/05/13 19:09:03 WARN AdminClientConfig: The configuration 'enable.auto.commit' was supplied but isn't a known config.\n",
      "24/05/13 19:09:03 WARN AdminClientConfig: The configuration 'max.poll.records' was supplied but isn't a known config.\n",
      "24/05/13 19:09:03 WARN AdminClientConfig: The configuration 'auto.offset.reset' was supplied but isn't a known config.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+------+----------+\n",
      "|sensor|media_temp|\n",
      "+------+----------+\n",
      "+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------+----------+\n",
      "|  sensor|media_temp|\n",
      "+--------+----------+\n",
      "|    NULL|      NULL|\n",
      "| sensor8|      48.3|\n",
      "|sensor43|      57.5|\n",
      "| sensor3|      28.8|\n",
      "|sensor15|      45.2|\n",
      "|sensor36|       8.2|\n",
      "|sensor22|      47.5|\n",
      "|sensor16|      58.5|\n",
      "|sensor21|      59.3|\n",
      "+--------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------+----------+\n",
      "|  sensor|media_temp|\n",
      "+--------+----------+\n",
      "|    NULL|      NULL|\n",
      "| sensor8|      48.3|\n",
      "|sensor43|      57.5|\n",
      "| sensor3|      28.8|\n",
      "|sensor15|      45.2|\n",
      "|sensor36|       8.2|\n",
      "|sensor22|      47.5|\n",
      "|sensor16|      58.5|\n",
      "|sensor21|      59.3|\n",
      "+--------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------+----------+\n",
      "|  sensor|media_temp|\n",
      "+--------+----------+\n",
      "|    NULL|      NULL|\n",
      "| sensor8|      48.3|\n",
      "|sensor43|      57.5|\n",
      "| sensor3|      28.8|\n",
      "|sensor15|      45.2|\n",
      "|sensor36|       8.2|\n",
      "|sensor22|      47.5|\n",
      "|sensor16|      58.5|\n",
      "|sensor21|      59.3|\n",
      "+--------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------+----------+\n",
      "|  sensor|media_temp|\n",
      "+--------+----------+\n",
      "|    NULL|      NULL|\n",
      "| sensor8|      48.3|\n",
      "|sensor43|      57.5|\n",
      "| sensor3|      28.8|\n",
      "|sensor15|      45.2|\n",
      "|sensor36|       8.2|\n",
      "|sensor22|      47.5|\n",
      "|sensor16|      58.5|\n",
      "|sensor21|      59.3|\n",
      "+--------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+--------+----------+\n",
      "|  sensor|media_temp|\n",
      "+--------+----------+\n",
      "|    NULL|      NULL|\n",
      "| sensor8|      48.3|\n",
      "|sensor43|      57.5|\n",
      "| sensor3|      28.8|\n",
      "|sensor15|      45.2|\n",
      "|sensor36|       8.2|\n",
      "|sensor22|      47.5|\n",
      "|sensor16|      58.5|\n",
      "|sensor21|      59.3|\n",
      "+--------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+--------+----------+\n",
      "|  sensor|media_temp|\n",
      "+--------+----------+\n",
      "|    NULL|      NULL|\n",
      "| sensor8|      48.3|\n",
      "|sensor43|      57.5|\n",
      "| sensor3|      28.8|\n",
      "|sensor15|      45.2|\n",
      "|sensor36|       8.2|\n",
      "|sensor22|      47.5|\n",
      "|sensor16|      58.5|\n",
      "|sensor21|      59.3|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Objeto que inicia a consulta ao streaming com formato de console\n",
    "query = df_media_temp_sensor.writeStream.outputMode(\"complete\").format(\"console\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da9572-972f-47ac-bb6b-1a169efe0890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1b1ef-587e-4f0a-9a43-d682066fafe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ae995-f966-460a-b819-94227c4765f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-374DM\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-374DM\",\"sensor\":\"sensor25\", \"data_evento\":\"2022-11-05T15:22:16.968007Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":42.0}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-476JW\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-476JW\",\"sensor\":\"sensor21\", \"data_evento\":\"2022-11-05T15:22:16.968353Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":59.3}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-377TT\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-377TT\",\"sensor\":\"sensor16\", \"data_evento\":\"2022-11-05T15:22:16.968423Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":58.5}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-417ZG\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-417ZG\",\"sensor\":\"sensor3\", \"data_evento\":\"2022-11-05T15:22:16.968476Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":28.8}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-806CG\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-806CG\",\"sensor\":\"sensor15\", \"data_evento\":\"2022-11-05T15:22:16.968526Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":45.2}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-851CT\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-851CT\",\"sensor\":\"sensor22\", \"data_evento\":\"2022-11-05T15:22:16.968578Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":47.5}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-872ZA\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-872ZA\",\"sensor\":\"sensor43\", \"data_evento\":\"2022-11-05T15:22:16.968625Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":57.5}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-037JC\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-037JC\",\"sensor\":\"sensor8\", \"data_evento\":\"2022-11-05T15:22:16.968673Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":48.3}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-560NJ\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-560NJ\",\"sensor\":\"sensor36\", \"data_evento\":\"2022-11-05T15:22:16.968722Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":8.2}}}\n",
    "{\"id_sensor\":\"S-DSA-MP6-CAP15-02468-458UK\",\"id_equipamento\":\"E-DSA-MP6-CAP15-13579-458UK\",\"sensor\":\"sensor35\", \"data_evento\":\"2022-11-05T15:22:16.968773Z\", \"padrao\":{\"formato\":\"iot:leitura:sensor:temp\", \"leitura\":{\"temperatura\":76.0}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73fcfd-d981-47b8-bb81-413634e1d417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fd2e6-06ed-47ab-beb9-e3f0e1550122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158bfa2-f192-4e92-9f54-55e0ba8f0b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b964e-617c-4078-a689-c20e3e8b97f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a02ff4-1661-4aa3-afde-358afd68ef0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
