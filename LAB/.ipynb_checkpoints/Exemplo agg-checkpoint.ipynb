{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1959f683-d1f8-4a81-a40d-396cc69de1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import sum,avg,max,col\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e8e3eab-b351-4c9e-9a35-4d1be90c1c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/14 22:44:10 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com')  \\\n",
    "        .master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# Create DataFrame\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8db9a478-db75-4427-801a-6fdfb990a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| bonus|\n",
      "+------+\n",
      "|173000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(F.sum(\"bonus\").alias(\"bonus\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e31ce7-d09d-4fe7-bc80-48f9869de47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|Sales     |3    |\n",
      "|Finance   |4    |\n",
      "|Marketing |2    |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\") \\\n",
    "    .agg(count(\"*\").alias(\"count\")\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814fd76c-1134-4eee-a28f-df136efd0e55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|department|state|count|\n",
      "+----------+-----+-----+\n",
      "|Sales     |NY   |2    |\n",
      "|Sales     |CA   |1    |\n",
      "|Finance   |CA   |2    |\n",
      "|Finance   |NY   |2    |\n",
      "|Marketing |NY   |1    |\n",
      "|Marketing |CA   |1    |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupby multiple columns & agg\n",
    "df.groupBy(\"department\",\"state\") \\\n",
    "    .agg(count(\"*\").alias(\"count\")) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87992891-20b4-4962-befb-40545168b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|Sales     |257000    |85666.66666666667|53000    |23000    |\n",
      "|Finance   |351000    |87750.0          |81000    |24000    |\n",
      "|Marketing |171000    |85500.0          |39000    |21000    |\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,col\n",
    "\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4b21b8-d66a-4e98-9283-eeea4e6dd26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|Sales     |257000    |85666.66666666667|53000    |23000    |\n",
      "|Finance   |351000    |87750.0          |81000    |24000    |\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using groupBy(), agg() and where()\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dadd4f64-8a2c-4a3d-89bb-fe4149852144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|       avg_salary|sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|     Sales|    257000|85666.66666666667|    53000|    23000|\n",
      "|   Finance|    351000|          87750.0|    81000|    24000|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PySpark SQL Group By AVG, SUM, MAX\n",
    "# Create Temporary table in PySpark\n",
    "df.createOrReplaceTempView(\"EMP\")\n",
    "\n",
    "# PySpark SQL\n",
    "sql_str=\"select department, sum(salary) as sum_salary,\" \\\n",
    "\"avg(salary) as avg_salary,\" \\\n",
    "\"sum(bonus) as sum_bonus,\" \\\n",
    "\"max(bonus) as max_bonus\" \\\n",
    "\" from EMP \"  \\\n",
    "\" group by department having sum_bonus >= 50000\"\n",
    "\n",
    "# Execute SQL\n",
    "spark.sql(sql_str).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e25a16af-d46b-4254-b53e-3d8b95d08a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|Sales     |3    |\n",
      "|Finance   |4    |\n",
      "|Marketing |2    |\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+-----+\n",
      "|department|state|count|\n",
      "+----------+-----+-----+\n",
      "|Sales     |NY   |2    |\n",
      "|Sales     |CA   |1    |\n",
      "|Finance   |CA   |2    |\n",
      "|Finance   |NY   |2    |\n",
      "|Marketing |NY   |1    |\n",
      "|Marketing |CA   |1    |\n",
      "+----------+-----+-----+\n",
      "\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|Sales     |257000    |85666.66666666667|53000    |23000    |\n",
      "|Finance   |351000    |87750.0          |81000    |24000    |\n",
      "|Marketing |171000    |85500.0          |39000    |21000    |\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|Sales     |257000    |85666.66666666667|53000    |23000    |\n",
      "|Finance   |351000    |87750.0          |81000    |24000    |\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|       avg_salary|sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|     Sales|    257000|85666.66666666667|    53000|    23000|\n",
      "|   Finance|    351000|          87750.0|    81000|    24000|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import sum,avg,max,col\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com') \\\n",
    "        .master(\"local[5]\").getOrCreate()\n",
    "\n",
    "# Create DataFrame\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Example 1 - PySpark groupby agg\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(count(\"*\").alias(\"count\")\n",
    "     ) \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "# Example 2 - groupby multiple columns & agg\n",
    "df.groupBy(\"department\",\"state\") \\\n",
    "    .agg(count(\"*\").alias(\"count\")\n",
    "     ) \\\n",
    "    .show(truncate=False)\n",
    "    \n",
    "# Example 3 - Multiple Aggregates\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "# Example 4 - Using where on Aggregates\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "# Example 5 - SQL group by agg\n",
    "# Create Temporary table in PySpark\n",
    "df.createOrReplaceTempView(\"EMP\")\n",
    "\n",
    "# PySpark SQL\n",
    "sql_str=\"select department, sum(salary) as sum_salary,\" \\\n",
    "\"avg(salary) as avg_salary,\" \\\n",
    "\"sum(bonus) as sum_bonus,\" \\\n",
    "\"max(bonus) as max_bonus\" \\\n",
    "\" from EMP \"  \\\n",
    "\" group by department having sum_bonus >= 50000\"\n",
    "spark.sql(sql_str).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451d572-7470-49a1-bcd9-a73879c2964f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
